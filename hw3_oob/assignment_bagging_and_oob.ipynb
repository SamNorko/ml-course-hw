{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "119c9460",
   "metadata": {},
   "source": [
    "## Home assignment 05: Bagging and OOB score\n",
    "\n",
    "Please, fill the lines in the code below.\n",
    "This is a simplified version of `BaggingRegressor` from `sklearn`. Please, notice, that `sklearn` API is **not preserved**.\n",
    "\n",
    "Your algorithm should be able to train different instances of the same model class on bootstrapped datasets and to provide [OOB score](https://en.wikipedia.org/wiki/Out-of-bag_error) for the training set.\n",
    "\n",
    "The model should be passed as model class with no explicit parameters and no parentheses.\n",
    "\n",
    "Example:\n",
    "```\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "bagging_regressor.fit(LinearRegression, X, y)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ecde34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "06110580",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedBaggingRegressor:\n",
    "    def __init__(self, num_bags, oob=False):\n",
    "        self.num_bags = num_bags\n",
    "        self.oob = oob\n",
    "        \n",
    "    def _generate_splits(self, data: np.ndarray):\n",
    "        '''\n",
    "        Generate indices for every bag and store in self.indices_list list\n",
    "        '''\n",
    "        self.indices_list = []\n",
    "        data_length = len(data)\n",
    "        for bag in range(self.num_bags):\n",
    "                indices = np.random.randint(0, data_length, data_length)\n",
    "                self.indices_list.append(indices)\n",
    "        \n",
    "    def fit(self, model_constructor, data, target):\n",
    "        '''\n",
    "        Fit model on every bag.\n",
    "        Model constructor with no parameters (and with no ()) is passed to this function.\n",
    "        \n",
    "        example:\n",
    "        \n",
    "        bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "        bagging_regressor.fit(LinearRegression, X, y)\n",
    "        '''\n",
    "        self.data = None\n",
    "        self.target = None\n",
    "        self._generate_splits(data)\n",
    "        assert len(set(list(map(len, self.indices_list)))) == 1, 'All bags should be of the same length!'\n",
    "        assert list(map(len, self.indices_list))[0] == len(data), 'All bags should contain `len(data)` number of elements!'\n",
    "        self.models_list = []\n",
    "        for bag in range(self.num_bags):\n",
    "            model = model_constructor()\n",
    "            data_bag, target_bag = data[self.indices_list[bag]], target[self.indices_list[bag]] # Your Code Here\n",
    "            self.models_list.append(model.fit(data_bag, target_bag)) # store fitted models here\n",
    "        if self.oob:\n",
    "            self.data = data\n",
    "            self.target = target\n",
    "        \n",
    "    def predict(self, data):\n",
    "        '''\n",
    "        Get average prediction for every object from passed dataset\n",
    "        '''\n",
    "        return np.mean(np.array([x.predict(data) for x in self.models_list]), axis=0)\n",
    "    \n",
    "    def _get_oob_predictions_from_every_model(self):\n",
    "        '''\n",
    "        Generates list of lists, where list i contains predictions for self.data[i] object\n",
    "        from all models, which have not seen this object during training phase\n",
    "        '''\n",
    "        list_of_predictions_lists = [[model.predict(self.data[i].reshape(1, -1)) for j, model in enumerate(self.models_list) if i not in self.indices_list[j]] for i in range(len(self.data))]  \n",
    "        self.list_of_predictions_lists = np.array(list_of_predictions_lists, dtype=object)\n",
    "    \n",
    "    def _get_averaged_oob_predictions(self):\n",
    "        '''\n",
    "        Compute average prediction for every object from training set.\n",
    "        If object has been used in all bags on training phase, return None instead of prediction\n",
    "        '''\n",
    "        self._get_oob_predictions_from_every_model()\n",
    "        print('___TEST___1')\n",
    "        self.oob_predictions = [np.mean(i) if len(i) != len(self.models_list) else None for i in self.list_of_predictions_lists] # Your Code Here\n",
    "        print('___TEST___2')\n",
    "        \n",
    "        \n",
    "    def OOB_score(self):\n",
    "        '''\n",
    "        Compute mean square error for all objects, which have at least one prediction\n",
    "        '''\n",
    "        self._get_averaged_oob_predictions()\n",
    "        #print(len(self.oob_predictions))\n",
    "        print(np.array([(self.target[i] - pred)**2 for i, pred in enumerate(self.oob_predictions) if pred is not None]))\n",
    "        return np.array([(self.target[i] - pred)**2 for i, pred in enumerate(self.oob_predictions) if pred is not None]).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cfa174f",
   "metadata": {},
   "source": [
    "### Local tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa2e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\ml-course\\ml-course-hw\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b54221c2",
   "metadata": {},
   "source": [
    "#### Simple tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "84c94a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]c:\\Projects\\ml-course\\ml-course-hw\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Projects\\ml-course\\ml-course-hw\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___TEST___1\n",
      "___TEST___2\n",
      "[2.35926418e-33 1.23259516e-32 5.00771878e-32 ... 4.93038066e-32\n",
      " 1.10933565e-31 0.00000000e+00]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "OOB error for linear dependency should be also close to zero!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m     oob_score \u001b[39m=\u001b[39m bagging_regressor\u001b[39m.\u001b[39mOOB_score()\n\u001b[0;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(oob_score)\n\u001b[1;32m---> 11\u001b[0m     \u001b[39massert\u001b[39;00m oob_score \u001b[39m<\u001b[39m \u001b[39m1e-6\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mOOB error for linear dependency should be also close to zero!\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     12\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mabs\u001b[39m(\n\u001b[0;32m     13\u001b[0m         np\u001b[39m.\u001b[39mmean(\n\u001b[0;32m     14\u001b[0m             \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlen\u001b[39m, bagging_regressor\u001b[39m.\u001b[39mlist_of_predictions_lists))\n\u001b[0;32m     15\u001b[0m         ) \u001b[39m/\u001b[39m bagging_regressor\u001b[39m.\u001b[39mnum_bags \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39mnp\u001b[39m.\u001b[39mexp(\u001b[39m1\u001b[39m)) \u001b[39m<\u001b[39m \u001b[39m0.1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mProbability of missing a bag should be close to theoretical value!\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSimple tests done!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: OOB error for linear dependency should be also close to zero!"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(100)):\n",
    "    X = np.random.randn(2000, 10)\n",
    "    y = np.mean(X, axis=1)\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    assert np.mean((predictions - y)**2) < 1e-6, 'Linear dependency should be fitted with almost zero error!'\n",
    "    assert bagging_regressor.oob, 'OOB feature must be turned on'\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    print(oob_score)\n",
    "    assert oob_score < 1e-6, 'OOB error for linear dependency should be also close to zero!'\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 0.1, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Simple tests done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4be4d037",
   "metadata": {},
   "source": [
    "#### Medium tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0cfd3a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:18<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___TEST___\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.94221337 -1.31426736 -0.93999077  0.8371804   0.78146644 -0.84766328\n -1.60175761  0.35428879  1.5697252   0.31568524 -0.99343914  1.32248738\n -0.29665033 -0.28022558  0.41648008  0.14461974  0.01194447 -1.32871934\n -0.43192878 -1.35665484 -0.03271855 -1.97899938 -0.46833181 -0.44827314\n -0.63787513 -1.49685677 -1.26057531  0.21075326 -0.91733084  0.94847847\n -0.45081447  1.25023298 -0.44454211 -0.35564658  0.98424418  0.95343567\n  1.38476089 -0.17780701 -0.35288811 -0.50729358  0.62875137  0.97060981\n -1.69310573  1.19027289  0.17289211  1.71734327  0.56615305  0.49476668\n  2.13510913 -0.07636466  0.31053292  1.51526788  1.06811197  1.92947664\n -1.97059253 -0.43253432 -1.73130045  0.87761368 -1.39816388  0.62329479\n -0.12922227 -1.774643   -0.259362    1.13987294  1.09064907  1.20680021\n -2.93108193  1.22849686  1.50986374  1.15266877 -2.05533638  0.68562031\n -0.5792697   0.53092564 -1.51788178  0.40992031 -0.57320292  0.74400182\n  1.04157972  0.49740212 -0.48013196  1.37820373  0.37715567  0.84474093\n  1.21157708 -0.85965067  0.76246701  0.53703321 -0.64660579  0.24535677\n -0.65673026 -0.42297744  0.83044027  1.22683374  1.06905578 -0.39303624\n -1.05881735 -0.82125171 -0.14911593  2.33128104  0.18519309 -0.09774862\n -0.30406359  0.19444748 -0.36554974  0.4254357  -2.07357721 -0.99587901\n -0.40243212  0.0730388  -0.33062421 -0.68790448  0.43558571 -0.03404269\n -0.58482728 -0.13522619  0.86932975  1.55609493  0.89040439  1.0271693\n  0.96431541  1.335879    2.55411455  1.41863256 -0.38125278  0.89260091\n  0.95399758 -0.75506552  0.63132756 -1.46234585  0.36591418  0.00548879\n -0.6887606  -0.20880602  0.51572608  0.42683528  0.18633926 -1.20257502\n  1.83165438 -0.01437741  1.57478134 -0.28520705  1.02181793  1.78538584\n  1.05159706 -0.80820755 -1.14063515  1.00062413  1.37669442  0.26569727].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m average_train_error \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean((predictions \u001b[39m-\u001b[39m y)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39massert\u001b[39;00m bagging_regressor\u001b[39m.\u001b[39moob, \u001b[39m'\u001b[39m\u001b[39mOOB feature must be turned on\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 9\u001b[0m oob_score \u001b[39m=\u001b[39m bagging_regressor\u001b[39m.\u001b[39;49mOOB_score()\n\u001b[0;32m     10\u001b[0m \u001b[39massert\u001b[39;00m oob_score \u001b[39m>\u001b[39m average_train_error, \u001b[39m'\u001b[39m\u001b[39mOOB error must be higher than train error due to overfitting!\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mabs\u001b[39m(\n\u001b[0;32m     12\u001b[0m     np\u001b[39m.\u001b[39mmean(\n\u001b[0;32m     13\u001b[0m         \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlen\u001b[39m, bagging_regressor\u001b[39m.\u001b[39mlist_of_predictions_lists))\n\u001b[0;32m     14\u001b[0m     ) \u001b[39m/\u001b[39m bagging_regressor\u001b[39m.\u001b[39mnum_bags \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39mnp\u001b[39m.\u001b[39mexp(\u001b[39m1\u001b[39m)) \u001b[39m<\u001b[39m \u001b[39m0.1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mProbability of missing a bag should be close to theoretical value!\u001b[39m\u001b[39m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[49], line 71\u001b[0m, in \u001b[0;36mSimplifiedBaggingRegressor.OOB_score\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mOOB_score\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     68\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39m    Compute mean square error for all objects, which have at least one prediction\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_averaged_oob_predictions()\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[49], line 63\u001b[0m, in \u001b[0;36mSimplifiedBaggingRegressor._get_averaged_oob_predictions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_averaged_oob_predictions\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39m    Compute average prediction for every object from training set.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m    If object has been used in all bags on training phase, return None instead of prediction\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_oob_predictions_from_every_model()\n\u001b[0;32m     64\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moob_predictions \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[49], line 52\u001b[0m, in \u001b[0;36mSimplifiedBaggingRegressor._get_oob_predictions_from_every_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39mGenerates list of lists, where list i contains predictions for self.data[i] object\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39mfrom all models, which have not seen this object during training phase\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m___TEST___\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m list_of_predictions_lists \u001b[39m=\u001b[39m [[model\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[i]) \u001b[39mfor\u001b[39;49;00m j, model \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodels_list) \u001b[39mif\u001b[39;49;00m i \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices_list[j]] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata))]\n\u001b[0;32m     53\u001b[0m \u001b[39mprint\u001b[39m(list_of_predictions_lists)\n\u001b[0;32m     54\u001b[0m \u001b[39m# Your Code Here\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[49], line 52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39mGenerates list of lists, where list i contains predictions for self.data[i] object\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39mfrom all models, which have not seen this object during training phase\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m___TEST___\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m list_of_predictions_lists \u001b[39m=\u001b[39m [[model\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[i]) \u001b[39mfor\u001b[39;49;00m j, model \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodels_list) \u001b[39mif\u001b[39;49;00m i \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices_list[j]] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata))]\n\u001b[0;32m     53\u001b[0m \u001b[39mprint\u001b[39m(list_of_predictions_lists)\n\u001b[0;32m     54\u001b[0m \u001b[39m# Your Code Here\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[49], line 52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39mGenerates list of lists, where list i contains predictions for self.data[i] object\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39mfrom all models, which have not seen this object during training phase\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m___TEST___\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m list_of_predictions_lists \u001b[39m=\u001b[39m [[model\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[i]) \u001b[39mfor\u001b[39;00m j, model \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels_list) \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices_list[j]] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata))]\n\u001b[0;32m     53\u001b[0m \u001b[39mprint\u001b[39m(list_of_predictions_lists)\n\u001b[0;32m     54\u001b[0m \u001b[39m# Your Code Here\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projects\\ml-course\\ml-course-hw\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:386\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    373\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[1;32mc:\\Projects\\ml-course\\ml-course-hw\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:369\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    367\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcoo\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    370\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[1;32mc:\\Projects\\ml-course\\ml-course-hw\\venv\\Lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Projects\\ml-course\\ml-course-hw\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:938\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    939\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    940\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    943\u001b[0m         )\n\u001b[0;32m    945\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    946\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    947\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    948\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    949\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.94221337 -1.31426736 -0.93999077  0.8371804   0.78146644 -0.84766328\n -1.60175761  0.35428879  1.5697252   0.31568524 -0.99343914  1.32248738\n -0.29665033 -0.28022558  0.41648008  0.14461974  0.01194447 -1.32871934\n -0.43192878 -1.35665484 -0.03271855 -1.97899938 -0.46833181 -0.44827314\n -0.63787513 -1.49685677 -1.26057531  0.21075326 -0.91733084  0.94847847\n -0.45081447  1.25023298 -0.44454211 -0.35564658  0.98424418  0.95343567\n  1.38476089 -0.17780701 -0.35288811 -0.50729358  0.62875137  0.97060981\n -1.69310573  1.19027289  0.17289211  1.71734327  0.56615305  0.49476668\n  2.13510913 -0.07636466  0.31053292  1.51526788  1.06811197  1.92947664\n -1.97059253 -0.43253432 -1.73130045  0.87761368 -1.39816388  0.62329479\n -0.12922227 -1.774643   -0.259362    1.13987294  1.09064907  1.20680021\n -2.93108193  1.22849686  1.50986374  1.15266877 -2.05533638  0.68562031\n -0.5792697   0.53092564 -1.51788178  0.40992031 -0.57320292  0.74400182\n  1.04157972  0.49740212 -0.48013196  1.37820373  0.37715567  0.84474093\n  1.21157708 -0.85965067  0.76246701  0.53703321 -0.64660579  0.24535677\n -0.65673026 -0.42297744  0.83044027  1.22683374  1.06905578 -0.39303624\n -1.05881735 -0.82125171 -0.14911593  2.33128104  0.18519309 -0.09774862\n -0.30406359  0.19444748 -0.36554974  0.4254357  -2.07357721 -0.99587901\n -0.40243212  0.0730388  -0.33062421 -0.68790448  0.43558571 -0.03404269\n -0.58482728 -0.13522619  0.86932975  1.55609493  0.89040439  1.0271693\n  0.96431541  1.335879    2.55411455  1.41863256 -0.38125278  0.89260091\n  0.95399758 -0.75506552  0.63132756 -1.46234585  0.36591418  0.00548879\n -0.6887606  -0.20880602  0.51572608  0.42683528  0.18633926 -1.20257502\n  1.83165438 -0.01437741  1.57478134 -0.28520705  1.02181793  1.78538584\n  1.05159706 -0.80820755 -1.14063515  1.00062413  1.37669442  0.26569727].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "    X = np.random.randn(200, 150)\n",
    "    y = np.random.randn(len(X))\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=20, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    average_train_error = np.mean((predictions - y)**2)\n",
    "    assert bagging_regressor.oob, 'OOB feature must be turned on'\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    assert oob_score > average_train_error, 'OOB error must be higher than train error due to overfitting!'\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 0.1, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Medium tests done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "725818ff",
   "metadata": {},
   "source": [
    "#### Complex tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f929d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "    X = np.random.randn(2000, 15)\n",
    "    y = np.random.randn(len(X))\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=100, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 1e-2, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Complex tests done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af170ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9535cb6d",
   "metadata": {},
   "source": [
    "Great job! Please, save `SimplifiedBaggingRegressor` to  `bagging.py` and submit your solution to the grading system!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
